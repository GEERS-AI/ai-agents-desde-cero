{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5afca013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2172d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d58cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain langchain-openai langchain-groq langchain-community langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17d57f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d9942cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n",
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because she found him too mean!\n"
     ]
    }
   ],
   "source": [
    "llm_model = os.environ[\"OPENAI_MODEL\"]\n",
    "# llm_model = \"moonshotai/kimi-k2-instruct\"\n",
    "print(llm_model)\n",
    "llm = ChatOpenAI(model=llm_model, temperature=0.1)\n",
    "# model = ChatGroq(model=llm_model, temperature=0.1)\n",
    "\n",
    "response = llm.invoke(\"Tell me a joke about data scientists\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e869ccb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I translated \"I love programming\" into French as \"J'adore la programmation.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant. Answer all questions to the best of your ability.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | llm # Chain\n",
    "\n",
    "ai_msg = chain.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Translate from English to French: I love programming.\"\n",
    "            ),\n",
    "            AIMessage(content=\"J'adore la programmation.\"),\n",
    "            HumanMessage(content=\"What did you just say?\"),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c64fd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Proxy design pattern is a structural design pattern that provides an object representing another object. It acts as an intermediary, controlling access to the original object. Here are the pros and cons of using the Proxy design pattern:\n",
       "\n",
       "### Pros:\n",
       "\n",
       "1. **Control Access**: Proxies can control access to the real object, allowing for additional security measures or access restrictions.\n",
       "\n",
       "2. **Lazy Initialization**: Proxies can delay the creation of expensive objects until they are actually needed, which can improve performance and resource management.\n",
       "\n",
       "3. **Remote Access**: In distributed systems, proxies can facilitate communication with remote objects, making it easier to work with remote services as if they were local.\n",
       "\n",
       "4. **Logging and Monitoring**: Proxies can be used to log requests and responses, providing a way to monitor interactions with the real object for debugging or auditing purposes.\n",
       "\n",
       "5. **Decoupling**: Proxies can decouple the client from the real object, allowing for easier changes to the real object without affecting the client.\n",
       "\n",
       "6. **Additional Functionality**: Proxies can add additional functionality (like caching, validation, etc.) without modifying the original object.\n",
       "\n",
       "### Cons:\n",
       "\n",
       "1. **Increased Complexity**: Introducing proxies can add complexity to the system, making it harder to understand and maintain.\n",
       "\n",
       "2. **Performance Overhead**: While proxies can improve performance in some cases (like lazy loading), they can also introduce overhead due to the additional layer of indirection, especially if not implemented efficiently.\n",
       "\n",
       "3. **Potential for Misuse**: If not designed carefully, proxies can lead to misuse or overuse, where they are used in situations where they are not necessary, complicating the architecture.\n",
       "\n",
       "4. **Debugging Difficulty**: The additional layer can make debugging more challenging, as it may not be immediately clear whether an issue lies with the proxy or the real object.\n",
       "\n",
       "5. **Tight Coupling with Proxy Logic**: If the client code is tightly coupled with the proxy's behavior, it may become difficult to switch to a different implementation or remove the proxy altogether.\n",
       "\n",
       "6. **Limited Functionality**: Proxies may not support all the functionalities of the real object, especially if they are not designed to forward all method calls properly.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The Proxy design pattern can be a powerful tool in software design, providing benefits such as access control, lazy initialization, and additional functionality. However, it also introduces complexity and potential performance overhead. It's essential to carefully consider the specific use case and requirements of your system before implementing this pattern."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an experienced software architect that assists a novice developer \n",
    "to design a system. \"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", SYSTEM_PROMPT),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    ")\n",
    "\n",
    "query = \"What are the prons and cons of the Proxy design pattern?\"\n",
    "\n",
    "qa_chain = qa_prompt | llm\n",
    "\n",
    "result = qa_chain.invoke(input=query)\n",
    "# print(result.content)\n",
    "display(Markdown(result.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ead4946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the advantages and disadvantages of using the Proxy design pattern?\n"
     ]
    }
   ],
   "source": [
    "CONTEXTUALIZED_PROMPT = \"\"\"Given a chat history and the latest developer's question\n",
    "    which might reference context in the chat history, formulate a standalone question\n",
    "    that can be understood without the chat history. Do NOT answer the question,\n",
    "    just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualized_qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", CONTEXTUALIZED_PROMPT),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\"human\", \"{question}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "contextualized_qa_chain = contextualized_qa_prompt | llm | StrOutputParser()\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "query = \"What are the prons and cons of the Proxy design pattern?\"\n",
    "\n",
    "ai_msg = contextualized_qa_chain.invoke(\n",
    "    {\n",
    "        'question': query, \n",
    "        'chat_history': chat_history.messages\n",
    "    }\n",
    ")\n",
    "print(ai_msg)\n",
    "\n",
    "chat_history.add_user_message(query)\n",
    "chat_history.add_ai_message(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a198b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, it is absolutely possible to combine the Proxy design pattern with other design patterns. In fact, doing so can enhance the functionality and flexibility of your system. Here are a few examples of how the Proxy pattern can be integrated with other design patterns:\n",
       "\n",
       "1. **Decorator Pattern**: The Proxy pattern can be combined with the Decorator pattern to add additional responsibilities to an object dynamically. For instance, you could use a Proxy to control access to a resource while also using a Decorator to add logging or caching functionality.\n",
       "\n",
       "2. **Singleton Pattern**: If you want to ensure that only one instance of a resource is accessed through a Proxy, you can combine it with the Singleton pattern. This way, the Proxy can manage access to the single instance of the resource, ensuring that it is only created once.\n",
       "\n",
       "3. **Observer Pattern**: A Proxy can act as an intermediary that notifies observers about changes in the subject it is proxying. This can be useful in scenarios where you want to monitor access or changes to a resource.\n",
       "\n",
       "4. **Factory Pattern**: You can use a Factory to create Proxy objects. This can be particularly useful if you want to create different types of Proxies (e.g., virtual, remote, or protection proxies) based on certain conditions.\n",
       "\n",
       "5. **Command Pattern**: If the Proxy is used to control access to a command, you can combine it with the Command pattern to encapsulate requests as objects. The Proxy can then manage the execution of these commands, adding additional logic such as logging or access control.\n",
       "\n",
       "6. **Strategy Pattern**: You can use a Proxy to switch between different strategies at runtime. For example, a Proxy could decide which strategy to use based on the current state of the application or user permissions.\n",
       "\n",
       "7. **Adapter Pattern**: If you need to adapt an interface to a different one, you can use a Proxy as an Adapter. This allows you to control access to the adapted object while also providing a different interface.\n",
       "\n",
       "When combining design patterns, it's essential to ensure that the resulting architecture remains clear and maintainable. Each pattern should serve a specific purpose, and the interactions between them should be well-defined to avoid unnecessary complexity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def contextualized_question(input: dict):\n",
    "        if input.get(\"chat_history\"):\n",
    "            return contextualized_qa_chain\n",
    "        else:\n",
    "            return input[\"question\"]\n",
    "\n",
    "qa_chain_with_memory = (\n",
    "         RunnablePassthrough.assign(\n",
    "            context=contextualized_question | qa_prompt | llm\n",
    "        )\n",
    "    )\n",
    "\n",
    "query = \"Can it be combined with other patterns?\"\n",
    "result = qa_chain_with_memory.invoke(\n",
    "    {\n",
    "        'question': query,  \n",
    "        'chat_history': chat_history.messages\n",
    "    }\n",
    ")\n",
    "\n",
    "display(Markdown(result['context'].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86e91488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Can it be combined with other patterns?',\n",
       " 'chat_history': [HumanMessage(content='What are the prons and cons of the Proxy design pattern?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='What are the advantages and disadvantages of using the Proxy design pattern?', additional_kwargs={}, response_metadata={})],\n",
       " 'context': AIMessage(content=\"Yes, it is absolutely possible to combine the Proxy design pattern with other design patterns. In fact, doing so can enhance the functionality and flexibility of your system. Here are a few examples of how the Proxy pattern can be integrated with other design patterns:\\n\\n1. **Decorator Pattern**: The Proxy pattern can be combined with the Decorator pattern to add additional responsibilities to an object dynamically. For instance, you could use a Proxy to control access to a resource while also using a Decorator to add logging or caching functionality.\\n\\n2. **Singleton Pattern**: If you want to ensure that only one instance of a resource is accessed through a Proxy, you can combine it with the Singleton pattern. This way, the Proxy can manage access to the single instance of the resource, ensuring that it is only created once.\\n\\n3. **Observer Pattern**: A Proxy can act as an intermediary that notifies observers about changes in the subject it is proxying. This can be useful in scenarios where you want to monitor access or changes to a resource.\\n\\n4. **Factory Pattern**: You can use a Factory to create Proxy objects. This can be particularly useful if you want to create different types of Proxies (e.g., virtual, remote, or protection proxies) based on certain conditions.\\n\\n5. **Command Pattern**: If the Proxy is used to control access to a command, you can combine it with the Command pattern to encapsulate requests as objects. The Proxy can then manage the execution of these commands, adding additional logic such as logging or access control.\\n\\n6. **Strategy Pattern**: You can use a Proxy to switch between different strategies at runtime. For example, a Proxy could decide which strategy to use based on the current state of the application or user permissions.\\n\\n7. **Adapter Pattern**: If you need to adapt an interface to a different one, you can use a Proxy as an Adapter. This allows you to control access to the adapted object while also providing a different interface.\\n\\nWhen combining design patterns, it's essential to ensure that the resulting architecture remains clear and maintainable. Each pattern should serve a specific purpose, and the interactions between them should be well-defined to avoid unnecessary complexity.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 441, 'prompt_tokens': 43, 'total_tokens': 484, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-C2nHr7Fn38uBzf2ohOW8FDkLGNZcf', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4aaadd44-4c72-4c2e-acd9-c23e0d3dd484-0', usage_metadata={'input_tokens': 43, 'output_tokens': 441, 'total_tokens': 484, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169513bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add dynamic few shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a463766d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: sad  \n",
      "Explanation: The antonym of \"happy\" is \"sad.\" While \"happy\" describes a state of joy, contentment, or pleasure, \"sad\" refers to a state of unhappiness, sorrow, or disappointment. These two words represent opposite emotional states.\n"
     ]
    }
   ],
   "source": [
    "zero_shot_prompt = PromptTemplate(\n",
    "    input_variables=['input'],\n",
    "    template=\"\"\"Return the antonym of the input given along with an explanation.\n",
    "    Input: {input}\n",
    "    Output:\n",
    "    Explanation:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Zero-shot\n",
    "zero_shot_chain = zero_shot_prompt | llm\n",
    "\n",
    "query = 'happy' # 'I am very sad but still have hope'\n",
    "result = zero_shot_chain.invoke(input=query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7305a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of a pretend task of creating antonyms.\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a839c88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return the antonym of the input given along with an explanation. \n",
      "\n",
      "Examples:\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: rainy\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # The list of examples available to select from.\n",
    "    examples,\n",
    "    # The embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(),\n",
    "    Chroma, # The database to store the examples with their embeddings\n",
    "    # The number of examples to produce.\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "similar_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Return the antonym of the input given along with an explanation. \\n\\nExamples:\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")\n",
    "\n",
    "print(similar_prompt.format(adjective=\"rainy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb4ec565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return the antonym of the input given along with an explanation. \n",
      "\n",
      "Examples:\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: rainy\n",
      "Output:\n",
      "\n",
      "Output: dry\n",
      "\n",
      "Explanation: \"Rainy\" refers to weather characterized by rain, which implies moisture and wet conditions. The antonym \"dry\" describes a lack of moisture, indicating clear or arid conditions, which contrasts with the idea of rain.\n"
     ]
    }
   ],
   "source": [
    "# Few-shot\n",
    "few_shot_chain = similar_prompt | llm\n",
    "\n",
    "query = 'rainy' # 'I am very sad but still have hope'\n",
    "print(similar_prompt.format(adjective=query))\n",
    "print()\n",
    "result = few_shot_chain.invoke(input=query)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c22ca2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FormattedAntonym(antonym='dry', explanation=\"The antonym 'dry' contrasts with 'rainy' as it describes weather conditions that lack moisture, while 'rainy' indicates the presence of rain.\")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FormattedAntonym(BaseModel):\n",
    "    antonym: str = Field(description=\"An antonym for the input word or phrase.\")\n",
    "    explanation: str = Field(description=\"A short explanation of how the antonym was generated\")\n",
    "\n",
    "llm_with_structure = llm.with_structured_output(FormattedAntonym)\n",
    "\n",
    "few_shot_chain1 = similar_prompt | llm_with_structure\n",
    "result = few_shot_chain1.invoke(input=query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "651e9c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'antonym': 'dry',\n",
       " 'explanation': \"The antonym 'dry' contrasts with 'rainy' as it describes weather conditions that lack moisture, while 'rainy' indicates the presence of rain.\"}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result.model_dump_json()\n",
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a88ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e7f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03baad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_desde_cero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
